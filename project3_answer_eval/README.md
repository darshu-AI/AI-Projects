## Answer Evaluation using Semantic Similarity (NLP)

## Overview  
This Natural Language Processing (NLP) project evaluates a student’s descriptive answer by comparing it with an ideal answer.
The system uses sentence embeddings to measure meaning similarity instead of keyword matching.
A Streamlit web app is provided for easy interaction.

## Algorithm Used  
Sentence Embeddings (Semantic Similarity)
Cosine Similarity

## Tech Stack  
Python  
Sentence-Transformers 
Scikit-learn
Streamlit  

## Inputs
Question ID – Used to fetch the corresponding ideal answer from the dataset
Student answer (text)

## Output  
Similarity score (0 to 1)
Feedback (Correct / Partially Correct / Needs Improvement)

## Project Structure  
data/ – Dataset containing question IDs and ideal answers
models/ – Pre-trained sentence embedding model (weights excluded)  
app/ – Streamlit user interface  
train_embeddings.py – Generates sentence embeddings  
requirements.txt – Project Dependencies  

## How to Run  
Install dependencies:  
pip install -r requirements.txt  

## Generate embeddings:  
python train_embeddings.py  

## Run the application:  
streamlit run app/streamlit_app.py  

## Note  
Pre-trained model files are excluded from the repository due to GitHub file size limits.  
They can be regenerated by running the training script.
